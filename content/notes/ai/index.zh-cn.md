---
title: "ai分享总结"
date: 2025-01-22
tags:
  - AI
---

## 可行性 + 路线

数据处理架构 + 系统工程 + 应用的范式是不确定的，是小企业家的机会，补齐模型做不了的事情，底部是非常多的模型。但是模型和算法的范式是确定的，是大企业做的事。大模型蒸馏方式变成小模型效果比不过从0开始训练小模型。

数据抓取 - 清洗 - 然后做个应用 （cursor内部是集成了agent，不仅仅是模型知识和推理，而是有能力了）

不要被范式限制： 而是考虑它能做什么，去体验它。 比如通过模型识别意图，然后通过抠图工具实现抠图，然后再通过xx实现什么，这是一个pipeline， 数据+工程+算法全栈都可以做，能力不一定100%有50%就OK， 我的底线很低我可以提升一下不管别人怎样，不一定要用大语言模型

Faas是一个服务，或者servless是服务，那么文本也可以成为服务： 每天给我推送5条AI消息，只能是英文并且。。 最后执行任务，然后发布到公众号，可以成为一个服务。可以自己实现代码，成为一个服务。 代码是生产力。

选出垂直场景，而不是单点解决

## agent vs copilot

agent有环境感知，制定计划，执行任务，然后完成目标（主驾）。 copilot是助手，你给指令，然后帮你完成任务，这是需要prompt能力，需要探索，还需要业务场景能力。


模型不是能回答所有问题的 ，比如 训练的时候时间是什么时候，知识有欠缺，肯定回答不上来。->  

所以一般需要结合api 然后回答（compound ai sys /  agentic system) -> 固定的pipeline

## 范式

- Agents -> llm基于任务目标、环境信息动态做决策 ，流程是不确定
- 单agent
- 多agent: 主从模式(主模式规划分派任务）/平等协作模式 （都可以决策，给谁做）
- computer use / web agent ： 自动化测试指令是自动生成的， 这个区别是指令是agent动态生成的

---

## 1. **统计+数据 ≠ 真正的智能**

### 1.1 数据驱动的局限性

- **依赖统计模型**：当前的许多人工智能系统主要基于统计学和大数据分析，通过海量数据训练模型来完成特定任务。
- **缺乏真正理解**：这些系统虽然能够处理复杂问题，但它们并不具备人类的“理解”能力。它们只是根据输入数据生成输出结果，而无法解释“为什么这么做”。

### 1.2 黑箱问题

- **不可解释性**：随着深度学习等技术的发展，人工智能的决策过程变得越来越复杂，甚至人类开发者也无法完全理解其内部机制。
- **信任危机**：这种“黑箱”特性使得人工智能在某些关键领域（如医疗、法律）的应用面临挑战。

## 2. **人工智能的层次划分**

为了更好地理解人工智能的构成和应用，可以将其划分为以下五个层次：

### 2.1 基础设施

- **硬件支持**：包括高性能计算设备（如GPU、TPU）、云计算平台以及传感器等硬件设施。
- **数据资源**：海量数据是人工智能的基础，数据的质量和多样性直接影响模型的效果。

### 2.2 算法

- **核心逻辑**：算法是人工智能的核心，决定了系统的运行方式。常见的算法包括机器学习、深度学习、强化学习等。
- **优化与创新**：不断优化现有算法并开发新的算法，是推动人工智能进步的关键。

### 2.3 技术

- **通用能力**：这一层关注人工智能的具体技术实现，例如自然语言处理（NLP）、计算机视觉、语音识别等。
- **跨领域融合**：这些技术可以应用于多个行业，并为后续解决方案提供技术支持。

### 2.4 技术点

- **细分功能**：技术点是对技术的进一步细化，例如情感分析、图像分割、推荐系统等。
- **模块化设计**：将复杂的技术分解为独立的功能模块，便于开发和集成。

### 2.5 行业解决方案

- **场景落地**：最终目标是将人工智能技术应用于具体的行业场景，例如智慧医疗、自动驾驶、金融科技等。
- **定制化服务**：根据不同行业的需求，提供针对性的解决方案，解决实际问题。

---


## GPT能做什么

### 核心能力
- **授业解惑**  
  - 无私心、耐心，能够提供清晰且易于理解的答案。
  - 具备类比、预测和按步骤输出的能力，适合教学和指导场景。

### 高级能力
- **理解复杂想法**  
  - 语言翻译、语气和风格的翻译、跨领域翻译。
  - 理解复杂的概念（如人类的笑话）并生成相关内容。

- **空间与视觉能力**  
  - 结合工具（如Stable Diffusion）生成符合预期的图片。
  - 通过文本描述生成小人或简单的视觉内容。

- **3D模型能力**  
  - 支持生成或描述3D模型的基础信息。

- **代码理解能力**  
  - 能够通过多个步骤组合工具实现用户意图，提供解决方案。

- **数学能力**  
  - 解法正确，支持基础到中等难度的数学问题求解。

- **与世界交互**  
  - 调用API、发送邮件、浏览网页等，具备一定的任务执行能力。

- **实体交互**  
  - 尽管无法直接看到或执行动作，但可以通过语言接口理解环境、任务、行动和反馈。

- **与人类交互**  
  - 推理他人心理状态的能力强，能够根据上下文生成符合人类期望的内容。

---

## GPT的缺陷

尽管GPT功能强大，但仍存在一些局限性：
- **缺乏计划性**  
  - 在文本生成时缺乏全局规划能力，尤其在需要心算或多步推理时表现较弱（自回归模型的固有限制）。

- **固化模型**  
  - 模型一旦训练完成就无法快速学习或从经验中归纳总结，缺乏动态调整能力。

- **因果推理不足**  
  - 对于需要溯因推理的问题，模型可能无法提供准确答案。

---

## 如何与GPT交互

1. **非结构化数据的结构化**  
   - 将复杂、模糊的需求转化为清晰、结构化的输入，提高模型的理解和输出质量。

2. **One-shot 学习**  
   - 提供知识背景和已知条件，明确求解目标，帮助模型快速生成解决方案。

3. **结合外部工具**  
   - 利用API调用、插件或其他工具扩展GPT的功能，解决特定领域的复杂问题。

---

## 未来的机会在哪

### AI的机会
- **快速数字化**  
  - 降低物理建模的成本，将非结构化数据转化为结构化数据。

- **助手革命**  
  - 一切都可以从“助手”角度出发，专注于解决问题，而非单纯追求便宜或效率。

### 抖音 vs 快手案例
- 抖音的成功在于让普通用户通过视频+音频快速发布内容，而非依赖算法优化。这说明了简单易用的工具在高频场景下的巨大潜力。

---

## 场景特征

- **广泛性**  
  - 应用场景覆盖多个领域，包括教育、医疗、娱乐等。

- **高频使用**  
  - 用户需求频繁，能够快速获得反馈。

- **快速反馈**  
  - 输出结果即时可见，便于迭代优化。

- **目的函数明确**  
  - 每次交互都有明确的目标，减少歧义。

- **中低决策维度**  
  - 大多数任务不需要复杂的多维决策，适合当前AI的能力范围。

---

## GPT为什么这么厉害

### 基于概率和特征的语言模型
- GPT基于概率和特征进行建模，而非传统的标记化方法。例如，“我在北京天（安门）天（气）”这种模式识别能力体现了其对语言深层次结构的理解。

### 语言承载智慧
- 语言是人类智慧的载体，GPT通过多层结构压缩和学习这些信息，从而具备了跨领域的理解和生成能力。

### 当前两种主要模式
1. **Fine-tune（调优）**  
   - 不做标记，通过微调适应特定任务。

2. **超文本模型**  
   - 知识库无需调优，直接利用预训练模型生成内容。

### Long-chain 的可能性
- Long-chain（长链推理）可能是未来发展方向之一，进一步提升模型在复杂任务中的表现。
